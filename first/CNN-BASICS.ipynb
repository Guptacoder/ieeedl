{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>What is a CNN?</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>A CNN is a neural network that typically contains several types of layers, one of which is a <em>convolutional layer, as well as pooling, and activation</em> layers.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cnn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>What is <strong>CONVOLUTION</strong>?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ConvNets derive their name from the <font color=\"red\">“convolution”</font> operator. The primary purpose of Convolution in case of a ConvNet is to extract features from the input image. Convolution preserves the spatial relationship between pixels by learning image features using small squares of input data. </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>INTUITIVELY</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>every image can be considered as a matrix of pixel values. Consider a 5 x 5 image whose pixel values are only 0 and 1 (note that for a grayscale image, pixel values range from 0 to 255, the green matrix below is a special case where pixel values are only 0 and 1):</h3>\n",
    "\n",
    "<img src=\"matrix.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Also, consider another 3 x 3 matrix as shown below:</h3>\n",
    "\n",
    "<img src=\"filter.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Then, the Convolution of the 5 x 5 image and the 3 x 3 matrix can be computed as shown in the animation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"giphy.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> We slide the orange matrix over our original image (green) by 1 pixel (also called ‘stride’) and for every position, we compute element wise multiplication (between the two matrices) and add the multiplication outputs to get the final integer which forms a single element of the output matrix (pink). Note that the 3×3 matrix “sees” only a part of the input image in each stride.</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>In CNN terminology, the 3×3 matrix is called a ‘filter‘ or ‘kernel’ or ‘feature detector’ and the matrix formed by sliding the filter over the image and computing the dot product is called the ‘Convolved Feature’ or ‘Activation Map’ or the ‘Feature Map‘. It is important to note that filters acts as feature detectors from the original input image.</h3>\n",
    "<img src=\"giphy (1).gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>What is <strong>POOLING</strong>?</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Spatial Pooling (also called subsampling or downsampling) reduces the dimensionality of each feature map but retains the most important information. Spatial Pooling can be of different types: Max, Average, Sum etc.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<h3>In case of Max Pooling, we define a spatial neighborhood (for example, a 2×2 window) and take the largest element from the rectified feature map within that window.</h3>\n",
    "\n",
    "<img src=\"pool.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>WHAT IS PADDING?</h1>\n",
    "<br></br>\n",
    "\n",
    "<h4>Sometimes filter does not fit perfectly fit the input image. We have two options:</h4>\n",
    "<br></br>\n",
    "<h4>\n",
    "Pad the picture with zeros (zero-padding) so that it fits</h4>\n",
    "<br></br>\n",
    "<h4>\n",
    "Drop the part of the image where the filter did not fit. This is called valid padding which keeps only valid part of the image.</h4>\n",
    "\n",
    "<img src=\"padding.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<img src=\"why-conv.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SOME FORMULAS</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<h3>for non padded or valid padded images or inputs</h3>\n",
    "\n",
    "for an input image or a matrix of <strong>height,width,depth(no of channels) n<sub>H</sub>,n<sub>W</sub>,n<sub>C</sub></strong> respectively, convolved with filter of <strong>height,width,depth(no of channels) f<sub>H</sub>,f<sub>W</sub>,f<sub>C</sub> and stride S</strong>\n",
    "<br></br>\n",
    "the output dimesions are given as \n",
    "\n",
    "<strong>\n",
    "height = ceil(( n<sub>H</sub> - f<sub>H</sub> / S ) +1 )\n",
    "</strong>\n",
    "<br></br>\n",
    "<strong>\n",
    "width  = ceil(( n<sub>W</sub> - f<sub>W</sub> / S ) + 1 )\n",
    "</strong>\n",
    "<br></br>\n",
    "<strong>\n",
    "depth  = f<sub>C</sub>\n",
    "</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<h3>for padded images or inputs</h3>\n",
    "\n",
    "for an input image or a matrix of <strong>height,width,depth(no of channels) and padding  n<sub>H</sub>,n<sub>W</sub>,n<sub>C</sub>,P</strong> respectively, convolved with filter of <strong>height,width,depth(no of channels) f<sub>H</sub>,f<sub>W</sub>,f<sub>C</sub> and stride S</strong>\n",
    "<br></br>\n",
    "the output dimesions are given as \n",
    "\n",
    "<strong>\n",
    "height = ceil(( n<sub>H</sub> - f<sub>H</sub> + 2P / S ) +1 )\n",
    "</strong>\n",
    "<br></br>\n",
    "<strong>\n",
    "width  = ceil(( n<sub>W</sub> - f<sub>W</sub>  + 2P / S ) + 1 )\n",
    "</strong>\n",
    "<br></br>\n",
    "<strong>\n",
    "depth  = f<sub>C</sub>\n",
    "</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>SAME GOES FOR POOLING</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
